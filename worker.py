# #/xray-agent/worker.py
from __future__ import annotations

import json
import signal
import traceback
import uuid
from typing import Any, Dict, Tuple, Optional

import httpx

from app.logger import log
from app.security.capacity import CapacityLimiter, CapacityPolicy
from app.settings import settings
import asyncio
import random
from contextlib import suppress

from app.redis_client import r
from app.queue import QUEUE_KEY, set_job_state, clear_issue_dedupe_cache
from app.xray import add_client, remove_client

# âœ… grpc.aio adapter (Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ async)
# Ð›ÐžÐ“Ð˜ÐšÐ ÐÐ• ÐœÐ•ÐÐ¯Ð•Ð¢Ð¡Ð¯: Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ¿Ð¾ÑÐ¾Ð± Ð²Ñ‹Ð·Ð¾Ð²Ð° (Ñ€Ð°Ð½ÑŒÑˆÐµ blocking->thread, Ñ‚ÐµÐ¿ÐµÑ€ÑŒ await)

# ðŸ›¡ï¸ Capacity limiter (Ð»Ð¸Ð¼Ð¸Ñ‚ Ñ‘Ð¼ÐºÐ¾ÑÑ‚Ð¸ inbound)

cap_limiter = CapacityLimiter()
cap_policy = CapacityPolicy(
    limit=int(getattr(settings, 'capacity_limit_per_inbound', 50) or 50),
    ttl_sec=int(getattr(settings, 'capacity_limit_ttl_sec', 120) or 120),
)


# -----------------------------
# Capacity helpers
# -----------------------------
async def _reserve_capacity(inbound_tag: str) -> bool:
    ok = await cap_limiter.reserve(inbound_tag, cap_policy)
    if not ok:
        log.warning(
            "capacity exceeded inbound_tag=%s limit=%s",
            inbound_tag,
            cap_policy.limit,
        )
    return ok

# -----------------------------
# Link builder (ÐºÐ°Ðº Ñƒ Ñ‚ÐµÐ±Ñ, Ð½Ð¾ Ð±ÐµÐ· Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑƒÑ‚ÐµÑ‡ÐµÐº)
# -----------------------------
def build_vless_link(user_uuid: str, email: str, flow: str) -> str:
    missing = []
    if not settings.public_host:
        missing.append("PUBLIC_HOST")
    if not settings.reality_sni:
        missing.append("REALITY_SNI")
    if not settings.reality_pbk:
        missing.append("REALITY_PBK")
    if not settings.reality_sid:
        missing.append("REALITY_SID")
    if missing:
        raise RuntimeError(f"Missing env params: {', '.join(missing)}")

    port = int(getattr(settings, "public_port", 443) or 443)
    fp = getattr(settings, "reality_fp", "chrome") or "chrome"
    flow_q = f"&flow={flow}" if flow else "&flow=xtls-rprx-vision"

    return (
        f"vless://{user_uuid}@{settings.public_host}:{port}"
        f"?encryption=none"
        f"{flow_q}"
        f"&security=reality"
        f"&sni={settings.reality_sni}"
        f"&fp={fp}"
        f"&pbk={settings.reality_pbk}"
        f"&sid={settings.reality_sid}"
        f"&type=tcp"
        f"#VPN-{email}"
    )


# -----------------------------
# Notify (async + retries)
# -----------------------------
def _notify_config() -> Tuple[Optional[str], Optional[str], int, int]:
    notify_url = getattr(settings, "notify_url", None)
    notify_key = getattr(settings, "notify_api_key", None)
    timeout = int(getattr(settings, "notify_timeout_sec", 10))
    retries = int(getattr(settings, "notify_retries", 3))
    return notify_url, notify_key, timeout, retries


async def notify_external(payload: Dict[str, Any]) -> Dict[str, Any]:
    notify_url, notify_key, timeout, retries = _notify_config()
    if not notify_url:
        return {"skipped": True, "reason": "NOTIFY_URL not set"}

    headers = {"Content-Type": "application/json"}
    if notify_key:
        headers["X-API-Key"] = notify_key

    last_err: str | None = None
    async with httpx.AsyncClient(timeout=timeout) as client:
        for attempt in range(1, retries + 1):
            try:
                resp = await client.post(notify_url, json=payload, headers=headers)
                if 200 <= resp.status_code < 300:
                    return {"skipped": False, "status_code": resp.status_code}

                last_err = f"HTTP {resp.status_code}: {resp.text[:300]}"
            except Exception as e:
                last_err = f"{type(e).__name__}: {e}"

            await asyncio.sleep(min(2 ** (attempt - 1), 8))

    raise RuntimeError(f"notify failed after {retries} attempts: {last_err}")


# -----------------------------
# Job utils
# -----------------------------
def _parse_job(raw: Any) -> dict:
    # decode_responses=True => raw ÑƒÐ¶Ðµ str
    if not isinstance(raw, str):
        raw = str(raw)
    return json.loads(raw)


def _require_field(obj: dict, key: str) -> Any:
    if key not in obj:
        raise ValueError(f"missing required field '{key}'")
    return obj[key]


def _safe_error(e: Exception) -> Dict[str, Any]:
    """
    Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð² Redis (Ñ‡Ñ‚Ð¾Ð±Ñ‹ API Ð½Ðµ ÑƒÑ‚ÐµÐºÐ°Ð»Ð¾ Ð²ÑÑ‘ Ð¿Ð¾Ð´Ñ€ÑÐ´).
    ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ traceback ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ settings.debug=True
    """
    base = {
        "type": type(e).__name__,
        "message": str(e)[:500],
    }
    if bool(getattr(settings, "debug", False)):
        base["trace"] = traceback.format_exc()[:8000]
    return base


async def handle(job: dict) -> dict:
    kind = _require_field(job, "kind")
    payload = _require_field(job, "payload")

    # NOTE: Ð›ÐžÐ“Ð˜ÐšÐ 1-Ð²-1 ÐºÐ°Ðº Ñ€Ð°Ð½ÑŒÑˆÐµ:
    # - add_client/remove_client/issue_client Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÑŽÑ‚ÑÑ Ð¸ Ñ€Ð°Ð½ÑŒÑˆÐµ, Ð¸ ÑÐµÐ¹Ñ‡Ð°Ñ.
    # - Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ: Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð²Ñ‹Ð·Ð¾Ð²Ñ‹ gRPC Ð½Ðµ Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑŽÑ‚ event-loop (grpc.aio),
    #   Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ _to_thread Ð±Ð¾Ð»ÑŒÑˆÐµ Ð½Ðµ Ð½ÑƒÐ¶ÐµÐ½.

    if kind == "add_client":
        user_uuid = _require_field(payload, "uuid")
        email = _require_field(payload, "email")
        inbound_tag = _require_field(payload, "inbound_tag")
        level = int(payload.get("level", 0))
        flow = payload.get("flow", "") or ""

        # ðŸ›¡ï¸ capacity reserve (anti-bomb)
        if not await _reserve_capacity(inbound_tag):
            return {"error": "CAPACITY_EXCEEDED", "limit": cap_policy.limit, "inbound_tag": inbound_tag}

        try:
            # âœ… grpc.aio: await
            return await asyncio.wait_for(
                add_client(user_uuid, email, inbound_tag, level, flow),
                timeout=float(getattr(settings, "grpc_timeout_sec", 10)),
            )
        except Exception:
            # ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ â€” Ð¾ÑÐ²Ð¾Ð±Ð¾Ð¶Ð´Ð°ÐµÐ¼ ÑÐ»Ð¾Ñ‚
            await cap_limiter.release(inbound_tag)
            raise

    if kind == "remove_client":
        email = _require_field(payload, "email")
        inbound_tag = _require_field(payload, "inbound_tag")

        # âœ… grpc.aio: await
        res = await asyncio.wait_for(
            remove_client(email, inbound_tag),
            timeout=float(getattr(settings, "grpc_timeout_sec", 10)),
        )

        # âœ… Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° ÐºÐµÑˆÐ°
        try:
            n = await clear_issue_dedupe_cache(telegram_id=email, inbound_tag=inbound_tag)
            log.info(f"[CACHE] cleared issue dedupe keys={n} email={email} tag={inbound_tag}")
        except Exception as e:
            log.error(f"[CACHE] clear dedupe failed email={email} tag={inbound_tag} err={str(e)[:200]}")

        return {"removed": res, "cache_cleared": True}

    if kind == "issue_client":
        telegram_id = str(_require_field(payload, "telegram_id")).strip()
        inbound_tag = str(payload.get("inbound_tag") or settings.default_inbound_tag)
        level = int(payload.get("level", 0))
        flow = payload.get("flow")
        flow = (flow if flow is not None else settings.default_flow) or ""

        user_uuid = str(uuid.uuid4())

        # ðŸ›¡ï¸ capacity reserve (anti-bomb)
        if not await _reserve_capacity(inbound_tag):
            return {"error": "CAPACITY_EXCEEDED", "limit": cap_policy.limit, "inbound_tag": inbound_tag}

        # 1) gRPC add user (async grpc.aio)
        try:
            await asyncio.wait_for(
                add_client(user_uuid, telegram_id, inbound_tag, level, flow),
            timeout=float(getattr(settings, "grpc_timeout_sec", 10)),
            )
        except Exception:
            await cap_limiter.release(inbound_tag)
            raise

        # 2) build link (fast)
        link = build_vless_link(user_uuid, telegram_id, flow)

        issued = {"uuid": user_uuid, "email": telegram_id, "inbound_tag": inbound_tag, "link": link}

        # 3) notify (async)
        try:
            notify_info = await asyncio.wait_for(
                notify_external(issued),
                timeout=float(getattr(settings, "notify_total_timeout_sec", 20)),
            )
        except Exception as e:
            notify_info = {"skipped": True, "reason": f"notify_failed: {type(e).__name__}: {str(e)[:200]}"}

        return {"issued": issued, "notify": notify_info}

    raise RuntimeError(f"unknown job kind={kind}")


# -----------------------------
# Main loop
# -----------------------------
class GracefulExit:
    def __init__(self):
        self._event = asyncio.Event()

    def request_stop(self) -> None:
        self._event.set()

    async def wait(self) -> None:
        await self._event.wait()

    def is_stopping(self) -> bool:
        return self._event.is_set()



# ÐŸÐ¾Ð´Ð±ÐµÑ€Ð¸ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð´ Ñ‚Ð²Ð¾ÑŽ Ð²ÐµÑ€ÑÐ¸ÑŽ redis-py:
try:
    from redis.exceptions import ConnectionError as RedisConnectionError, TimeoutError as RedisTimeoutError
except Exception:  # pragma: no cover
    RedisConnectionError = TimeoutError  # type: ignore
    RedisTimeoutError = TimeoutError  # type: ignore


async def _safe_set_job_state(job_id: str, state: str, **kwargs) -> None:
    """
    ÐÐ¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð´Ð°Ñ‘Ð¼ Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ð²Ð¾Ñ€ÐºÐµÑ€Ñƒ Ð¸Ð·-Ð·Ð° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÐ¸ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð² Redis.
    """
    try:
        # Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð¼ Ð²Ñ€ÐµÐ¼Ñ Ð½Ð° Ð·Ð°Ð¿Ð¸ÑÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð·Ð°Ð»Ð¸Ð¿Ð½ÑƒÑ‚ÑŒ Ð½Ð° ÑÐµÑ‚ÐµÐ²Ð¾Ð¼ Ñ„Ð»Ð°Ð¿Ðµ
        await asyncio.wait_for(set_job_state(job_id, state, **kwargs), timeout=3)
    except asyncio.CancelledError:
        # Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ Ð²Ð¾Ñ€ÐºÐµÑ€Ð° â€” Ð´Ð°Ñ‘Ð¼ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒÑÑ
        raise
    except Exception as e:
        log.error("set_job_state failed id=%s state=%s err=%r", job_id, state, e)


async def worker_loop():
    log.info("worker started queue=%s", QUEUE_KEY)
    stopper = GracefulExit()

    loop = asyncio.get_running_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, stopper.request_stop)
        except NotImplementedError:
            pass

    # backoff Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ñ Redis: Ñ€Ð°ÑÑ‚Ñ‘Ñ‚ Ð´Ð¾ 5Ñ, Ð¿Ð¾Ñ‚Ð¾Ð¼ ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¿Ñ€Ð¸ ÑƒÑÐ¿ÐµÑ…Ðµ
    backoff = 0.1
    backoff_max = 5.0

    while True:
        if stopper.is_stopping():
            log.info("worker stopping gracefully...")
            break

        # --- 1) Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ñ‡Ñ‚ÐµÐ½Ð¸Ðµ Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸ ---
        try:
            # brpop Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ½ÑƒÑ‚ÑŒ Ð¿Ñ€Ð¸ ÑÐµÑ‚ÐµÐ²Ð¾Ð¼ Ñ„Ð»Ð°Ð¿Ðµ â€” Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð¼ Ð²Ð½ÐµÑˆÐ½Ð¸Ð¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼
            item = await asyncio.wait_for(
                r.brpop([QUEUE_KEY], timeout=1),
                timeout=3,
            )

            backoff = 0.1  # ÑƒÑÐ¿ÐµÑ… -> ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ backoff
        except asyncio.TimeoutError:
            # Ð»Ð¸Ð±Ð¾ Ð½Ð°Ñˆ wait_for, Ð»Ð¸Ð±Ð¾ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚: ÑÑ‚Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ "idle"
            continue
        except asyncio.CancelledError:
            log.warning("worker cancelled -> stopping")
            break
        except (RedisConnectionError, RedisTimeoutError, OSError, ConnectionError) as e:
            log.error("redis brpop/connect failed err=%r; backoff=%.2fs", e, backoff)
            await asyncio.sleep(backoff + random.uniform(0, backoff * 0.2))
            backoff = min(backoff * 2, backoff_max)
            continue
        except Exception as e:
            # Ð»ÑŽÐ±Ð¾Ð¹ Ð½ÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐµÐ¹Ñ: Ð»Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ Ð½Ðµ Ð¿Ð°Ð´Ð°ÐµÐ¼
            log.exception("unexpected error in brpop err=%r", e)
            await asyncio.sleep(0.5)
            continue

        if item is None:
            continue

        _, raw = item

        try:
            job = _parse_job(raw)
        except Exception as e:
            log.error("invalid job payload err=%s raw=%r", e, raw)
            continue

        job_id = job.get("id")
        if not job_id:
            log.error("job without id: %r", job)
            continue

        # --- 2) Ð·Ð°Ð¿Ð¸ÑÑŒ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ: Ð½Ð¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð²Ð°Ð»Ð¸Ñ‚ÑŒ Ð²Ð¾Ñ€ÐºÐµÑ€ ---
        await _safe_set_job_state(job_id, "running")
        log.info("job running id=%s kind=%s", job_id, job.get("kind"))

        try:
            # --- 3) handle: Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ°Ðº ÐµÑÑ‚ÑŒ, Ð½Ð¾ Ð»Ð¾Ð²Ð¸Ð¼ CancelledError Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ ---
            res = await handle(job)
            if not isinstance(res, dict):
                res = {"raw": res}

            await _safe_set_job_state(job_id, "done", result=res)
            log.info("job done id=%s", job_id)

        except asyncio.CancelledError:
            # Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ â€” Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ð¾Ð¼ÐµÑ‚Ð¸Ñ‚ÑŒ, Ð½Ð¾ Ð½Ðµ Ð¾Ð±ÑÐ·Ð°Ð½Ñ‹ ÑƒÑÐ¿ÐµÑ‚ÑŒ
            with suppress(Exception):
                await _safe_set_job_state(job_id, "error", error={"type": "CancelledError", "msg": "worker stopping"})
            log.warning("job cancelled id=%s -> stopping worker", job_id)
            break

        except Exception as e:
            err_doc = _safe_error(e)
            await _safe_set_job_state(job_id, "error", error=err_doc)
            log.error("job error id=%s err=%s", job_id, err_doc)


def main():
    asyncio.run(worker_loop())


if __name__ == "__main__":
    main()